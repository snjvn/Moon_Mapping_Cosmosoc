{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971ee47e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.21\n",
      "  Downloading numpy-1.21.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-image 0.21.0 requires numpy>=1.21.1, but you have numpy 1.21.0 which is incompatible.\n",
      "scipy 1.11.1 requires numpy<1.28.0,>=1.21.6, but you have numpy 1.21.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires absl-py~=0.10, but you have absl-py 1.4.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires flatbuffers~=1.12.0, but you have flatbuffers 2.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires gast==0.3.3, but you have gast 0.4.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires grpcio~=1.32.0, but you have grpcio 1.48.2 which is incompatible.\n",
      "tensorflow 2.4.1 requires numpy~=1.19.2, but you have numpy 1.21.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires tensorflow-estimator<2.5.0,>=2.4.0, but you have tensorflow-estimator 2.6.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires termcolor~=1.1.0, but you have termcolor 2.1.0 which is incompatible.\n",
      "tensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.7.1 which is incompatible.\n",
      "tensorflow 2.4.1 requires wrapt~=1.12.1, but you have wrapt 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f27183",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'typeDict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#title           :Network.py\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#description     :Architecture file(Generator and Discriminator)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Modules\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Activation\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnormalization\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BatchNormalization\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-new/lib/python3.9/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomRotation\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKeras requires TensorFlow 2.2 or higher. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInstall TensorFlow via `pip install tensorflow`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-new/lib/python3.9/site-packages/keras/utils/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generic_utils\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data_utils\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m conv_utils\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses_utils\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-new/lib/python3.9/site-packages/keras/utils/io_utils.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     HDF5_OBJECT_HEADER_LIMIT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64512\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-new/lib/python3.9/site-packages/h5py/__init__.py:46\u001b[0m\n\u001b[1;32m     37\u001b[0m     _warn((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh5py is running against HDF5 \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m when it was built against \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis may cause problems\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_version_tuple),\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39mversion\u001b[38;5;241m.\u001b[39mhdf5_built_version_tuple)\n\u001b[1;32m     41\u001b[0m     ))\n\u001b[1;32m     44\u001b[0m _errors\u001b[38;5;241m.\u001b[39msilence_errors()\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_converters \u001b[38;5;28;01mas\u001b[39;00m _register_converters\n\u001b[1;32m     47\u001b[0m _register_converters()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mh5z\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _register_lzf\n",
      "File \u001b[0;32mh5py/_conv.pyx:1\u001b[0m, in \u001b[0;36minit h5py._conv\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:293\u001b[0m, in \u001b[0;36minit h5py.h5t\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-new/lib/python3.9/site-packages/numpy/__init__.py:328\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'typeDict'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#title           :Network.py\n",
    "#description     :Architecture file(Generator and Discriminator)\n",
    "#author          :Deepak Birla\n",
    "#date            :2018/10/30\n",
    "#usage           :from Network import Generator, Discriminator\n",
    "#python_version  :3.5.4 \n",
    "\n",
    "# Modules\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import UpSampling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import add\n",
    "\n",
    "\n",
    "# Residual block\n",
    "def res_block_gen(model, kernal_size, filters, strides):\n",
    "    \n",
    "    gen = model\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    # Using Parametric ReLU\n",
    "    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "        \n",
    "    model = add([gen, model])\n",
    "    \n",
    "    return model\n",
    "    \n",
    "    \n",
    "def up_sampling_block(model, kernal_size, filters, strides):\n",
    "    \n",
    "    # In place of Conv2D and UpSampling2D we can also use Conv2DTranspose (Both are used for Deconvolution)\n",
    "    # Even we can have our own function for deconvolution (i.e one made in Utils.py)\n",
    "    #model = Conv2DTranspose(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = Conv2D(filters = filters, kernel_size = kernal_size, strides = strides, padding = \"same\")(model)\n",
    "    model = UpSampling2D(size = 2)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def discriminator_block(model, filters, kernel_size, strides):\n",
    "    \n",
    "    model = Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding = \"same\")(model)\n",
    "    model = BatchNormalization(momentum = 0.5)(model)\n",
    "    model = LeakyReLU(alpha = 0.2)(model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
    "class Generator(object):\n",
    "\n",
    "    def __init__(self, noise_shape):\n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "\n",
    "    def generator(self):\n",
    "        \n",
    "\t    gen_input = Input(shape = self.noise_shape)\n",
    "\t    \n",
    "\t    model = Conv2D(filters = 64, kernel_size = 9, strides = 1, padding = \"same\")(gen_input)\n",
    "\t    model = PReLU(alpha_initializer='zeros', alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(model)\n",
    "\t    \n",
    "\t    gen_model = model\n",
    "        \n",
    "        # Using 16 Residual Blocks\n",
    "\t    for index in range(16):\n",
    "\t        model = res_block_gen(model, 3, 64, 1)\n",
    "\t    \n",
    "\t    model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(model)\n",
    "\t    model = BatchNormalization(momentum = 0.5)(model)\n",
    "\t    model = add([gen_model, model])\n",
    "\t    \n",
    "\t    # Using 2 UpSampling Blocks\n",
    "\t    for index in range(2):\n",
    "\t        model = up_sampling_block(model, 3, 256, 1)\n",
    "\t    \n",
    "\t    model = Conv2D(filters = 3, kernel_size = 9, strides = 1, padding = \"same\")(model)\n",
    "\t    model = Activation('tanh')(model)\n",
    "\t   \n",
    "\t    generator_model = Model(inputs = gen_input, outputs = model)\n",
    "        \n",
    "\t    return generator_model\n",
    "\n",
    "# Network Architecture is same as given in Paper https://arxiv.org/pdf/1609.04802.pdf\n",
    "class Discriminator(object):\n",
    "\n",
    "    def __init__(self, image_shape):\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "    \n",
    "    def discriminator(self):\n",
    "        \n",
    "        dis_input = Input(shape = self.image_shape)\n",
    "        \n",
    "        model = Conv2D(filters = 64, kernel_size = 3, strides = 1, padding = \"same\")(dis_input)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "        \n",
    "        model = discriminator_block(model, 64, 3, 2)\n",
    "        model = discriminator_block(model, 128, 3, 1)\n",
    "        model = discriminator_block(model, 128, 3, 2)\n",
    "        model = discriminator_block(model, 256, 3, 1)\n",
    "        model = discriminator_block(model, 256, 3, 2)\n",
    "        model = discriminator_block(model, 512, 3, 1)\n",
    "        model = discriminator_block(model, 512, 3, 2)\n",
    "        \n",
    "        model = Flatten()(model)\n",
    "        model = Dense(1024)(model)\n",
    "        model = LeakyReLU(alpha = 0.2)(model)\n",
    "       \n",
    "        model = Dense(1)(model)\n",
    "        model = Activation('sigmoid')(model) \n",
    "        \n",
    "        discriminator_model = Model(inputs = dis_input, outputs = model)\n",
    "        \n",
    "        return discriminator_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f816a6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
