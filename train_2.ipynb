{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c54b902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 11:33:14.329804: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 11:33:14.401674: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c79c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tensorflow.config.list_physical_devices()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc98f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config=ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "\n",
    "import tensorflow as tf\n",
    "gpu = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85df5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import Generator, Discriminator\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "# import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Lambda, Input\n",
    "\n",
    "import skimage.transform\n",
    "from skimage import data, io, filters\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from skimage.transform import rescale, resize\n",
    "# from scipy.misc import imresize\n",
    "import os\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c36904f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol\n",
      "data loaded\n",
      "data processed\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "shape_hr = (1200,9369,1)\n",
    "\n",
    "def vgg_loss(y_true, y_pred):\n",
    "    \n",
    "    vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=shape_hr)\n",
    "    vgg19.trainable = False\n",
    "    for l in vgg19.layers:\n",
    "        l.trainable = False\n",
    "    loss_model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
    "    loss_model.trainable = False\n",
    "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
    "\n",
    "def get_gan_network(discriminator, shape, generator, optimizer):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = Input(shape=shape)\n",
    "    x = generator(gan_input)\n",
    "    print(x.shape)\n",
    "    gan_output = discriminator(x)\n",
    "    gan = Model(inputs=gan_input, outputs=[x,gan_output])\n",
    "    gan.compile(loss=[vgg_loss, \"binary_crossentropy\"],\n",
    "                loss_weights=[1., 1e-3],\n",
    "                optimizer=optimizer)\n",
    "\n",
    "    return gan\n",
    "\n",
    "\n",
    "def load_path(path):\n",
    "    directories = []\n",
    "    if os.path.isdir(path):\n",
    "        directories.append(path)\n",
    "    for elem in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path,elem)):\n",
    "            directories = directories + load_path(os.path.join(path,elem))\n",
    "            directories.append(os.path.join(path,elem))\n",
    "    return directories\n",
    "\n",
    "def normalize(input_data):\n",
    "\n",
    "    return ((input_data.astype(np.float32) - 127.5)/127.5)\n",
    "    \n",
    "def load_data_from_dirs(dirs, ext):\n",
    "    files = []\n",
    "    file_names = []\n",
    "    count = 0\n",
    "    for d in dirs:\n",
    "        for f in os.listdir(d): \n",
    "            if f.endswith(ext):\n",
    "                image = io.imread(os.path.join(d,f))\n",
    "#                 print(\"noice\",image[:,:,0])\n",
    "                if len(image.shape) > 2:\n",
    "#                     print(\"lol\")\n",
    "                    files.append(image[:,:,0])\n",
    "                    file_names.append(os.path.join(d,f))\n",
    "                else:\n",
    "                    files.append(image)\n",
    "                    file_names.append(os.path.join(d,f))\n",
    "                count = count + 1\n",
    "    return files     \n",
    "            \n",
    "# def load_data_from_dirs_resize(dirs, ext, size):\n",
    "#     files = []\n",
    "#     file_names = []\n",
    "#     count = 0\n",
    "#     for d in dirs:\n",
    "#         for f in os.listdir(d): \n",
    "#             if f.endswith(ext):\n",
    "#                 files.append(resize(io.imread(os.path.join(d,f)), size))\n",
    "#                 file_names.append(os.path.join(d,f))\n",
    "#                 count = count + 1\n",
    "#     return files     \n",
    "                        \n",
    "          \n",
    "def load_data(directory, ext):\n",
    "\n",
    "    files = load_data_from_dirs(load_path(directory), ext)\n",
    "    return files\n",
    "\n",
    "\n",
    "files = load_data(\"./resized_cropped_tmc/X_train\", \".png\")\n",
    "x_train_lr = files\n",
    "files = load_data(\"./resized_cropped_tmc/X_test\", \".png\")\n",
    "x_test_lr = files\n",
    "print(\"lol\")\n",
    "files = load_data(\"./ohrc_final_final/y_train\", \".png\")\n",
    "x_train_hr = files\n",
    "files = load_data(\"./ohrc_final_final/y_test\", \".png\")\n",
    "x_test_hr = files\n",
    "\n",
    "print(\"data loaded\")\n",
    "\n",
    "\n",
    "def hr_images(images):\n",
    "    images_hr = array(images)\n",
    "    return images_hr\n",
    "\n",
    "# def lr_images(images_real , downscale):\n",
    "    \n",
    "#     images = []\n",
    "#     for img in  range(len(images_real)):\n",
    "#         images.append(imresize(images_real[img], [images_real[img].shape[0]//downscale,images_real[img].shape[1]//downscale], interp='bicubic', mode=None))\n",
    "#     images_lr = array(images)\n",
    "#     return images_lr\n",
    "\n",
    "# def preprocess_HR(x):\n",
    "#     return np.divide(x.astype(np.float32), 127.5) - np.ones_like(x,dtype=np.float32)\n",
    "\n",
    "\n",
    "# def deprocess_HR(x):\n",
    "#     input_data = (input_data + 1) * 127.5\n",
    "#     return input_data.astype(np.uint8) \n",
    "\n",
    "\n",
    "# def preprocess_LR(x):\n",
    "#     return np.divide(x.astype(np.float32), 255.)\n",
    "\n",
    "\n",
    "# def deprocess_LR(x):\n",
    "#     x = np.clip(x*255, 0, 255)\n",
    "#     return x\n",
    "\n",
    "\n",
    "    \n",
    "def denormalize(input_data):\n",
    "    input_data = (input_data + 1) * 127.5\n",
    "    return input_data.astype(np.uint8) \n",
    "\n",
    "# def deprocess_LRS(x):\n",
    "#     x = np.clip(x*255, 0, 255)\n",
    "#     return x.astype(np.uint8)\n",
    "\n",
    "\n",
    "x_train_hr = hr_images(x_train_hr)\n",
    "\n",
    "x_train_lr = hr_images(x_train_lr)\n",
    "# x_train_lr = normalize(x_train_lr)\n",
    "\n",
    "\n",
    "x_test_hr = hr_images(x_test_hr)\n",
    "# x_test_hr = normalize(x_test_hr)\n",
    "\n",
    "x_test_lr = hr_images(x_test_lr)\n",
    "# x_test_lr = normalize(x_test_lr)\n",
    "\n",
    "print(\"data processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "978c49b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 9369, 1200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_hr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c9281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-06 11:34:37.250514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-06 11:34:37.742246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46889 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:9e:00.0, compute capability: 7.5\n",
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 260, 1476, 3)\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1200, 9369, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1200, 9369, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 260, 1476, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1200, 9369, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1200, 9369, 1), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 260, 1476, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"model_1\" (type Functional).\n\nInput 0 of layer \"conv2d_37\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 260, 1476, 3)\n\nCall arguments received by layer \"model_1\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 260, 1476, 3), dtype=float32)\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m             discriminator\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./output/dis_model\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m e)\n\u001b[1;32m     83\u001b[0m             gan\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./output/gan_model\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m e)\n\u001b[0;32m---> 85\u001b[0m train()\n",
      "Cell \u001b[0;32mIn[6], line 46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs, batch_size)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m#     shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, 3)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     shape_lr\n\u001b[0;32m---> 46\u001b[0m     gan \u001b[39m=\u001b[39m get_gan_network(discriminator, shape_lr, generator, adam)\n\u001b[1;32m     48\u001b[0m     \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     49\u001b[0m         \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m15\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m e, \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m15\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36mget_gan_network\u001b[0;34m(discriminator, shape, generator, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m x \u001b[39m=\u001b[39m generator(gan_input)\n\u001b[1;32m     18\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 19\u001b[0m gan_output \u001b[39m=\u001b[39m discriminator(x)\n\u001b[1;32m     20\u001b[0m gan \u001b[39m=\u001b[39m Model(inputs\u001b[39m=\u001b[39mgan_input, outputs\u001b[39m=\u001b[39m[x,gan_output])\n\u001b[1;32m     21\u001b[0m gan\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m[vgg_loss, \u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     22\u001b[0m             loss_weights\u001b[39m=\u001b[39m[\u001b[39m1.\u001b[39m, \u001b[39m1e-3\u001b[39m],\n\u001b[1;32m     23\u001b[0m             optimizer\u001b[39m=\u001b[39moptimizer)\n",
      "File \u001b[0;32m~/miniconda3/envs/bathy/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/bathy/lib/python3.10/site-packages/keras/engine/input_spec.py:277\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    272\u001b[0m             value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mvalue\n\u001b[1;32m    273\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape_as_list[\u001b[39mint\u001b[39m(axis)] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\n\u001b[1;32m    274\u001b[0m             value,\n\u001b[1;32m    275\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m         }:\n\u001b[0;32m--> 277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    278\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    279\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: expected axis \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof input shape to have value \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mbut received input with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m             )\n\u001b[1;32m    284\u001b[0m \u001b[39m# Check shape.\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape\u001b[39m.\u001b[39mrank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"model_1\" (type Functional).\n\nInput 0 of layer \"conv2d_37\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 260, 1476, 3)\n\nCall arguments received by layer \"model_1\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 260, 1476, 3), dtype=float32)\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "def plot_generated_images(epoch,generator, examples=3 , dim=(1, 3), figsize=(15, 5)):\n",
    "    \n",
    "    rand_nums = np.random.randint(0, x_test_hr.shape[0], size=examples)\n",
    "    image_batch_hr = x_test_hr[rand_nums]\n",
    "    image_batch_lr = x_test_lr[rand_nums]\n",
    "    gen_img = generator.predict(image_batch_lr)\n",
    "    generated_image = gen_img\n",
    "#     image_batch_lr = image_batch_lr\n",
    "    \n",
    "    #generated_image = deprocess_HR(generator.predict(image_batch_lr))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 1)\n",
    "    plt.imshow(image_batch_lr[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "        \n",
    "    plt.subplot(dim[0], dim[1], 2)\n",
    "    plt.imshow(generated_image[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(dim[0], dim[1], 3)\n",
    "    plt.imshow(image_batch_hr[1], interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/gan_generated_image_epoch_%d.png' % epoch)\n",
    "    \n",
    "\n",
    "def train(epochs=1, batch_size=1):\n",
    "\n",
    "    downscale_factor = 4\n",
    "    \n",
    "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
    "    shape_lr = (65,369,1)\n",
    "    \n",
    "    generator = Generator(shape_lr).generator()\n",
    "    discriminator = Discriminator(shape_hr).discriminator()\n",
    "\n",
    "    adam = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    generator.compile(loss=vgg_loss, optimizer=adam)\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=adam)\n",
    "    \n",
    "#     shape = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, 3)\n",
    "    shape_lr\n",
    "    gan = get_gan_network(discriminator, shape_lr, generator, adam)\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "        for _ in range(batch_count):\n",
    "            \n",
    "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
    "            \n",
    "            image_batch_hr = x_train_hr[rand_nums]\n",
    "            image_batch_lr = x_train_lr[rand_nums]\n",
    "            generated_images_sr = generator.predict(image_batch_lr)\n",
    "\n",
    "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
    "            \n",
    "            discriminator.trainable = True\n",
    "            \n",
    "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
    "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
    "            #d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "            \n",
    "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
    "            image_batch_hr = x_train_hr[rand_nums]\n",
    "            image_batch_lr = x_train_lr[rand_nums]\n",
    "\n",
    "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
    "            discriminator.trainable = False\n",
    "            loss_gan = gan.train_on_batch(image_batch_lr, [image_batch_hr,gan_Y])\n",
    "            \n",
    "        print(\"Loss HR , Loss LR, Loss GAN\")\n",
    "        print(d_loss_real, d_loss_fake, loss_gan)\n",
    "\n",
    "        if e == 1 or e % 5 == 0:\n",
    "            plot_generated_images(e, generator)\n",
    "        if e % 300 == 0:\n",
    "            generator.save('./output/gen_model%d.h5' % e)\n",
    "            discriminator.save('./output/dis_model%d.h5' % e)\n",
    "            gan.save('./output/gan_model%d.h5' % e)\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2462fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tensorflow.config.list_physical_devices('GPU')))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4d996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc97fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
