{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0703cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using PyTorch backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TLX] [!] samples exists ...\n",
      "[TLX] [!] models exists ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tensorlayerx/__init__.py:45: UserWarning: The version of the backend you have installed does not match the specified backend version and may not work, please install version torch 1.10.0.\n",
      "  warnings.warn(\"The version of the backend you have installed does not match the specified backend version \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['TL_BACKEND'] = 'tensorflow' # Just modify this line, easily switch to any framework! PyTorch will coming soon!\n",
    "# os.environ['TL_BACKEND'] = 'mindspore'\n",
    "# os.environ['TL_BACKEND'] = 'paddle'\n",
    "os.environ['TL_BACKEND'] = 'torch'\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorlayerx as tlx\n",
    "from tensorlayerx.dataflow import Dataset, DataLoader\n",
    "from srgan import SRGAN_g, SRGAN_d\n",
    "from config import config\n",
    "from tensorlayerx.vision.transforms import Compose, RandomCrop, Normalize, RandomFlipHorizontal, Resize, HWC2CHW\n",
    "import vgg\n",
    "from tensorlayerx.model import TrainOneStep\n",
    "from tensorlayerx.nn import Module\n",
    "import cv2\n",
    "# tlx.set_device('GPU')\n",
    "batch_size = 8\n",
    "n_epoch_init = config.TRAIN.n_epoch_init\n",
    "n_epoch = config.TRAIN.n_epoch\n",
    "# create folders to save result images and trained models\n",
    "save_dir = \"samples\"\n",
    "tlx.files.exists_or_mkdir(save_dir)\n",
    "checkpoint_dir = \"models\"\n",
    "tlx.files.exists_or_mkdir(checkpoint_dir)\n",
    "\n",
    "hr_transform = Compose([\n",
    "    RandomCrop(size=(1200, 9369)),\n",
    "])\n",
    "nor = Compose([Normalize(mean=(127.5), std=(127.5), data_format='HWC'),\n",
    "              HWC2CHW()])\n",
    "lr_transform = Resize(size=(65, 369))\n",
    "\n",
    "train_hr_imgs = tlx.vision.load_images(path=config.TRAIN.hr_img_path, n_threads = 32)\n",
    "train_lr_imgs = tlx.vision.load_images(path=config.TRAIN.lr_img_path, n_threads = 32)\n",
    "\n",
    "class TrainData(Dataset):\n",
    "\n",
    "    def __init__(self, hr_trans=hr_transform, lr_trans=lr_transform):\n",
    "        self.train_hr_imgs = train_hr_imgs\n",
    "        self.train_lr_imgs= train_lr_imgs\n",
    "        self.hr_trans = hr_trans\n",
    "        self.lr_trans = lr_trans\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.train_hr_imgs[index]\n",
    "        hr_patch = self.hr_trans(img)\n",
    "        img_2=self.train_lr_imgs[index]\n",
    "        lr_patch = self.lr_trans(img_2)\n",
    "        return nor(lr_patch), nor(hr_patch)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_hr_imgs)\n",
    "\n",
    "\n",
    "class WithLoss_init(Module):\n",
    "    def __init__(self, G_net, loss_fn):\n",
    "        super(WithLoss_init, self).__init__()\n",
    "        self.net = G_net\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, lr, hr):\n",
    "        out = self.net(lr)\n",
    "        loss = self.loss_fn(out, hr)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class WithLoss_D(Module):\n",
    "    def __init__(self, D_net, G_net, loss_fn):\n",
    "        super(WithLoss_D, self).__init__()\n",
    "        self.D_net = D_net\n",
    "        self.G_net = G_net\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, lr, hr):\n",
    "        fake_patchs = self.G_net(lr)\n",
    "        logits_fake = self.D_net(fake_patchs)\n",
    "        logits_real = self.D_net(hr)\n",
    "        d_loss1 = self.loss_fn(logits_real, tlx.ones_like(logits_real))\n",
    "        d_loss1 = tlx.ops.reduce_mean(d_loss1)\n",
    "        d_loss2 = self.loss_fn(logits_fake, tlx.zeros_like(logits_fake))\n",
    "        d_loss2 = tlx.ops.reduce_mean(d_loss2)\n",
    "        d_loss = d_loss1 + d_loss2\n",
    "        return d_loss\n",
    "\n",
    "\n",
    "class WithLoss_G(Module):\n",
    "    def __init__(self, D_net, G_net, vgg, loss_fn1, loss_fn2):\n",
    "        super(WithLoss_G, self).__init__()\n",
    "        self.D_net = D_net\n",
    "        self.G_net = G_net\n",
    "        self.vgg = vgg\n",
    "        self.loss_fn1 = loss_fn1\n",
    "        self.loss_fn2 = loss_fn2\n",
    "\n",
    "    def forward(self, lr, hr):\n",
    "        fake_patchs = self.G_net(lr)\n",
    "        logits_fake = self.D_net(fake_patchs)\n",
    "        feature_fake = self.vgg((fake_patchs + 1) / 2.)\n",
    "        feature_real = self.vgg((hr + 1) / 2.)\n",
    "        g_gan_loss = 1e-3 * self.loss_fn1(logits_fake, tlx.ones_like(logits_fake))\n",
    "        g_gan_loss = tlx.ops.reduce_mean(g_gan_loss)\n",
    "        mse_loss = self.loss_fn2(fake_patchs, hr)\n",
    "        vgg_loss = 2e-6 * self.loss_fn2(feature_fake, feature_real)\n",
    "        g_loss = mse_loss + vgg_loss + g_gan_loss\n",
    "        return g_loss\n",
    "\n",
    "\n",
    "G = SRGAN_g()\n",
    "D = SRGAN_d()\n",
    "VGG = vgg.VGG19(pretrained=True, end_with='pool4', mode='dynamic')\n",
    "# automatic init layers weights shape with input tensor.\n",
    "# Calculating and filling 'in_channels' of each layer is a very troublesome thing.\n",
    "# So, just use 'init_build' with input shape. 'in_channels' of each layer will be automaticlly set.\n",
    "G.init_build(tlx.nn.Input(shape=(8, 3, 96, 96)))\n",
    "D.init_build(tlx.nn.Input(shape=(8, 3, 384, 384)))\n",
    "\n",
    "\n",
    "def train():\n",
    "    G.set_train()\n",
    "    D.set_train()\n",
    "    VGG.set_eval()\n",
    "    train_ds = TrainData()\n",
    "    train_ds_img_nums = len(train_ds)\n",
    "    train_ds = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    lr_v = tlx.optimizers.lr.StepDecay(learning_rate=0.05, step_size=1000, gamma=0.1, last_epoch=-1, verbose=True)\n",
    "    g_optimizer_init = tlx.optimizers.Momentum(lr_v, 0.9)\n",
    "    g_optimizer = tlx.optimizers.Momentum(lr_v, 0.9)\n",
    "    d_optimizer = tlx.optimizers.Momentum(lr_v, 0.9)\n",
    "    g_weights = G.trainable_weights\n",
    "    d_weights = D.trainable_weights\n",
    "    net_with_loss_init = WithLoss_init(G, loss_fn=tlx.losses.mean_squared_error)\n",
    "    net_with_loss_D = WithLoss_D(D_net=D, G_net=G, loss_fn=tlx.losses.sigmoid_cross_entropy)\n",
    "    net_with_loss_G = WithLoss_G(D_net=D, G_net=G, vgg=VGG, loss_fn1=tlx.losses.sigmoid_cross_entropy,\n",
    "                                 loss_fn2=tlx.losses.mean_squared_error)\n",
    "\n",
    "    trainforinit = TrainOneStep(net_with_loss_init, optimizer=g_optimizer_init, train_weights=g_weights)\n",
    "    trainforG = TrainOneStep(net_with_loss_G, optimizer=g_optimizer, train_weights=g_weights)\n",
    "    trainforD = TrainOneStep(net_with_loss_D, optimizer=d_optimizer, train_weights=d_weights)\n",
    "\n",
    "    # initialize learning (G)\n",
    "    n_step_epoch = round(train_ds_img_nums // batch_size)\n",
    "    for epoch in range(n_epoch_init):\n",
    "        for step, (lr_patch, hr_patch) in enumerate(train_ds):\n",
    "            step_time = time.time()\n",
    "            loss = trainforinit(lr_patch, hr_patch)\n",
    "            print(\"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, mse: {:.3f} \".format(\n",
    "                epoch, n_epoch_init, step, n_step_epoch, time.time() - step_time, float(loss)))\n",
    "\n",
    "    # adversarial learning (G, D)\n",
    "    n_step_epoch = round(train_ds_img_nums // batch_size)\n",
    "    for epoch in range(n_epoch):\n",
    "        for step, (lr_patch, hr_patch) in enumerate(train_ds):\n",
    "            step_time = time.time()\n",
    "            loss_g = trainforG(lr_patch, hr_patch)\n",
    "            loss_d = trainforD(lr_patch, hr_patch)\n",
    "            print(\n",
    "                \"Epoch: [{}/{}] step: [{}/{}] time: {:.3f}s, g_loss:{:.3f}, d_loss: {:.3f}\".format(\n",
    "                    epoch, n_epoch, step, n_step_epoch, time.time() - step_time, float(loss_g), float(loss_d)))\n",
    "        # dynamic learning rate update\n",
    "        lr_v.step()\n",
    "\n",
    "        if (epoch != 0) and (epoch % 10 == 0):\n",
    "            G.save_weights(os.path.join(checkpoint_dir, 'g.npz'), format='npz_dict')\n",
    "            D.save_weights(os.path.join(checkpoint_dir, 'd.npz'), format='npz_dict')\n",
    "\n",
    "def evaluate():\n",
    "    ###====================== PRE-LOAD DATA ===========================###\n",
    "    valid_hr_imgs = tlx.vision.load_images(path=config.VALID.hr_img_path )\n",
    "    ###========================LOAD WEIGHTS ============================###\n",
    "    G.load_weights(os.path.join(checkpoint_dir, 'g.npz'), format='npz_dict')\n",
    "    G.set_eval()\n",
    "    imid = 0  # 0: 企鹅  81: 蝴蝶 53: 鸟  64: 古堡\n",
    "    valid_hr_img = valid_hr_imgs[imid]\n",
    "    valid_lr_img = np.asarray(valid_hr_img)\n",
    "    hr_size1 = [valid_lr_img.shape[0], valid_lr_img.shape[1]]\n",
    "    valid_lr_img = cv2.resize(valid_lr_img, dsize=(hr_size1[1] // 4, hr_size1[0] // 4))\n",
    "    valid_lr_img_tensor = (valid_lr_img / 127.5) - 1  # rescale to ［－1, 1]\n",
    "\n",
    "\n",
    "    valid_lr_img_tensor = np.asarray(valid_lr_img_tensor, dtype=np.float32)\n",
    "    valid_lr_img_tensor = np.transpose(valid_lr_img_tensor,axes=[2, 0, 1])\n",
    "    valid_lr_img_tensor = valid_lr_img_tensor[np.newaxis, :, :, :]\n",
    "    valid_lr_img_tensor= tlx.ops.convert_to_tensor(valid_lr_img_tensor)\n",
    "    size = [valid_lr_img.shape[0], valid_lr_img.shape[1]]\n",
    "\n",
    "    out = tlx.ops.convert_to_numpy(G(valid_lr_img_tensor))\n",
    "    out = np.asarray((out + 1) * 127.5, dtype=np.uint8)\n",
    "    out = np.transpose(out[0], axes=[1, 2, 0])\n",
    "    print(\"LR size: %s /  generated HR size: %s\" % (size, out.shape))  # LR size: (339, 510, 3) /  gen HR size: (1, 1356, 2040, 3)\n",
    "    print(\"[*] save images\")\n",
    "    tlx.vision.save_image(out, file_name='valid_gen.png', path=save_dir)\n",
    "    tlx.vision.save_image(valid_lr_img, file_name='valid_lr.png', path=save_dir)\n",
    "    tlx.vision.save_image(valid_hr_img, file_name='valid_hr.png', path=save_dir)\n",
    "    out_bicu = cv2.resize(valid_lr_img, dsize = [size[1] * 4, size[0] * 4], interpolation = cv2.INTER_CUBIC)\n",
    "    tlx.vision.save_image(out_bicu, file_name='valid_hr_cubic.png', path=save_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument('--mode', type=str, default='train', help='train, eval')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    tlx.global_flag['mode'] = args.mode\n",
    "\n",
    "    if tlx.global_flag['mode'] == 'train':\n",
    "        train()\n",
    "    elif tlx.global_flag['mode'] == 'eval':\n",
    "        evaluate()\n",
    "    else:\n",
    "        raise Exception(\"Unknow --mode\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81967fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ubuntu/disk/SRGAN-master'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d06a67cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: easydict in /home/ubuntu/.local/lib/python3.10/site-packages (1.10)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2550eee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\r\n",
      "  return torch._C._cuda_getDeviceCount() > 0\r\n",
      "False\r\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import torch; print(torch.cuda.is_available())\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b76ddf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://download.pytorch.org/whl/cu113/torch_stable.html\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.1+cu113 (from versions: 1.11.0, 1.11.0+cu113, 1.12.0, 1.12.0+cu113, 1.12.1, 1.12.1+cu113, 1.13.0, 1.13.1, 2.0.0, 2.0.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.1+cu113\u001b[0m\u001b[31m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
      "Collecting torch-scatter\n",
      "  Downloading torch_scatter-2.1.1.tar.gz (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.6/107.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-scatter\n",
      "  Building wheel for torch-scatter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-scatter: filename=torch_scatter-2.1.1-cp310-cp310-linux_x86_64.whl size=484337 sha256=b78e370c8f18f9d22003540e9230bdda93b89312b6aac1d51c206c68bad4d7b6\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ef/67/58/6566a3b61c6ec0f2ca0c2c324cd035ef2955601f0fb3197d5f\n",
      "Successfully built torch-scatter\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch-scatter\n",
      "Successfully installed torch-scatter-2.1.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
      "Requirement already satisfied: torch-scatter in /home/ubuntu/.local/lib/python3.10/site-packages (2.1.1)\n",
      "Collecting torch-sparse\n",
      "  Downloading torch_sparse-0.6.17.tar.gz (209 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/lib/python3/dist-packages (from torch-sparse) (1.8.0)\n",
      "Building wheels for collected packages: torch-sparse\n",
      "  Building wheel for torch-sparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-sparse: filename=torch_sparse-0.6.17-cp310-cp310-linux_x86_64.whl size=1029724 sha256=81e6109cf653e8c31f6d0cdc50d5a36a2c604f467431ae7ac1de1176399c67cc\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/67/25/e7/037b58fa47ba781444fd101a2f06c63a9d4e967ca6b910c53a\n",
      "Successfully built torch-sparse\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch-sparse\n",
      "Successfully installed torch-sparse-0.6.17\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
      "Collecting torch-cluster\n",
      "  Downloading torch_cluster-1.6.1.tar.gz (53 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m719.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/lib/python3/dist-packages (from torch-cluster) (1.8.0)\n",
      "Building wheels for collected packages: torch-cluster\n",
      "  Building wheel for torch-cluster (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-cluster: filename=torch_cluster-1.6.1-cp310-cp310-linux_x86_64.whl size=691466 sha256=56f00159cc2df88ea8d38174cb9fe18cd09c3eae62db559bf56b0ec44c571e37\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/2e/ed/ac/1df43a8ff5b9bd2f44042636b98a60b2b4027d3ce8e8a3185f\n",
      "Successfully built torch-cluster\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: torch-cluster\n",
      "Successfully installed torch-cluster-1.6.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m369.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm (from torch-geometric)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m383.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m329.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.10/site-packages (from torch-geometric) (1.24.3)\n",
      "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from torch-geometric) (1.8.0)\n",
      "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch-geometric) (3.0.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from torch-geometric) (2.25.1)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from torch-geometric) (2.4.7)\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.10/site-packages (from torch-geometric) (1.3.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from torch-geometric) (5.9.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m378.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m351.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: torch-geometric\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torch-geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=553fd751f726cb21b4c98bc1e208df47935f235ce04594ecc1b1635b15b3c16c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built torch-geometric\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tqdm, torch-geometric\n",
      "Successfully installed torch-geometric-2.3.1 tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio==0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "!pip3 install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip3 install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip3 install torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip3 install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b1350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
